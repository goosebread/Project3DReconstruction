{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 3D reconstruction using 2 image\n",
    "\n",
    "Key References\n",
    "- https://www.opencvhelp.org/tutorials/advanced/reconstruction-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import random as rd\n",
    "from typing import TYPE_CHECKING\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyrender\n",
    "import scipy.spatial.transform as sci_trans\n",
    "\n",
    "from project_3d_reconstruction.rendering import render_helper as rh\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "\n",
    "import pyvista as pv\n",
    "import trimesh\n",
    "\n",
    "from project_3d_reconstruction.point_cloud_to_mesh import (\n",
    "    point_cloud_to_mesh as pcloud,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Generate simple scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading c:\\Code\\Project3DReconstruction\\mesh_files\\coral_4\\untitled.dae\n",
      "Done loading\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = os.path.abspath(\n",
    "    os.path.join(\n",
    "        os.path.abspath(\"pyrender_basic_reconstruction.ipynb\"), \"..\", \"..\", \"mesh_files\"\n",
    "    )\n",
    ")\n",
    "OBJECTS = [\n",
    "    # os.path.join(FILE_PATH, \"pyrender_examples\", \"drill.obj\"),\n",
    "    os.path.join(FILE_PATH, \"coral_4\", \"untitled.dae\"),\n",
    "    # os.path.join(FILE_PATH, \"duck\", \"duck5.obj\"),\n",
    "    # os.path.join(FILE_PATH, \"cat\", \"watermelon.obj\"),\n",
    "]\n",
    "\n",
    "renderer = rh.RenderHelper()\n",
    "\n",
    "# Load in mesh files\n",
    "names = []\n",
    "for file_path in OBJECTS:\n",
    "    print(f\"Loading {file_path}\")\n",
    "    name = file_path.split(\"\\\\\")[-2]  # warning slash is different for linux vs windows\n",
    "    names.append(name)\n",
    "    renderer.loadFromPath(file_path, name)\n",
    "print(\"Done loading\")\n",
    "\n",
    "# Place them in the world\n",
    "renderer.addFromMeshDict(\"coral_4\", rh.positionOnly(0, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# test image from two perspectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it got annoying making edits in render helper so its here now (TODO move it back)\n",
    "# NOTE z is out, y is up (image y might be flipped), x is right\n",
    "def toOriginPose2(x, y, z):\n",
    "    # azimuth from xz plane\n",
    "    az_rad = np.arctan2(x, z)\n",
    "    # rotation about y axis\n",
    "    Ry = np.array(\n",
    "        [\n",
    "            [np.cos(az_rad), 0, np.sin(az_rad)],\n",
    "            [0, 1, 0],\n",
    "            [-np.sin(az_rad), 0, np.cos(az_rad)],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    el_rad = np.arctan2(-y, np.sqrt(x**2 + z**2))\n",
    "    Rx = np.array(\n",
    "        [\n",
    "            [1, 0, 0],\n",
    "            [0, np.cos(el_rad), -np.sin(el_rad)],\n",
    "            [0, np.sin(el_rad), np.cos(el_rad)],\n",
    "        ]\n",
    "    )\n",
    "    R = Ry @ Rx\n",
    "    Rstack = np.hstack((R, np.array([[x, y, z]]).T))\n",
    "    return np.vstack((Rstack, np.array([[0, 0, 0, 1]])))\n",
    "\n",
    "\n",
    "# wrapper for easy even spacing\n",
    "def toOriginPose3(az_rad, el_rad, radius):\n",
    "    y = radius * np.sin(el_rad)\n",
    "    rproj = radius * np.cos(el_rad)\n",
    "    x = rproj * np.sin(az_rad)\n",
    "    z = rproj * np.cos(az_rad)\n",
    "    return toOriginPose2(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# save many images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render many views in a spiral pattern\n",
    "poses = []\n",
    "images = []\n",
    "numPoses = 40\n",
    "azSpacing = 2.0 * np.pi / numPoses\n",
    "elSpacing = np.pi * 2.0 / (3 * numPoses)\n",
    "for i in range(numPoses):\n",
    "    pose1 = toOriginPose3(\n",
    "        azSpacing * 2 * i, -np.pi / 3.0 + elSpacing * i, 1\n",
    "    )  # 0.5) for drill #2.5)#for duck\n",
    "    renderer.moveCamera(pose1)\n",
    "    renderer.render(show_image=False, image_filename=\"test\" + str(i) + \".png\")\n",
    "    poses.append(pose1)\n",
    "    # TODO optimize this out if we're low on memory\n",
    "    images.append(cv.imread(\"test\" + str(i) + \".png\"))\n",
    "\n",
    "# actual extrinsics\n",
    "# print(pose1)\n",
    "# print(pose2)\n",
    "# relativePose = np.matmul(np.linalg.inv(pose1), pose2)\n",
    "# print(relativePose)\n",
    "\n",
    "gray_0 = cv.cvtColor(images[0], cv.COLOR_BGR2GRAY)\n",
    "gray_1 = cv.cvtColor(images[1], cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# ifig, iaxs = plt.subplots(ncols=numPoses, figsize=(8, 8))\n",
    "# for i in range(numPoses):\n",
    "#     iaxs[i].imshow(images[i], origin=\"lower\")\n",
    "# ifig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Detect SIFT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f7c624d310>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def opponentSIFT(img):\n",
    "    # Step 1 convert to opponent color space\n",
    "    # TODO optimize\n",
    "    B = img[:, :, 0]\n",
    "    G = img[:, :, 1]\n",
    "    R = img[:, :, 2]\n",
    "\n",
    "    O1 = np.divide((R - G), np.sqrt(2))\n",
    "    O2 = np.divide((R + G - 2 * B), np.sqrt(6))\n",
    "    O3 = np.divide((R + G + B), np.sqrt(3))\n",
    "    # visually check opponent color space\n",
    "    # cv.imwrite('sift_keypointsO1.jpg',np.uint8(O1))\n",
    "    # cv.imwrite('sift_keypointsO2.jpg',np.uint8(O2))\n",
    "    # cv.imwrite('sift_keypointsO3.jpg',np.uint8(O3))\n",
    "\n",
    "    # Step 2 use Harris-Laplace point detector on intensity channel (o3)\n",
    "    # TODO use a real point detector or figure out what parameters to use with cv SIFT\n",
    "    # use this space to specify additional parameters\n",
    "    sift = cv.SIFT_create()\n",
    "    # sift = cv.SIFT_create(nfeatures=1000)\n",
    "\n",
    "    kp = sift.detect(np.uint8(O3), None)\n",
    "\n",
    "    # Step 3 compute descriptors for each opponent channel\n",
    "    _, des1 = sift.compute(np.uint8(O1), kp)\n",
    "    _, des2 = sift.compute(np.uint8(O2), kp)\n",
    "    _, des3 = sift.compute(np.uint8(O3), kp)\n",
    "\n",
    "    # combine into one large descriptor\n",
    "    des = np.concatenate((des1, des2, des3), axis=1)\n",
    "\n",
    "    return kp, des\n",
    "\n",
    "\n",
    "kpList = []\n",
    "desList = []\n",
    "for i in range(numPoses):\n",
    "    kp, des = opponentSIFT(images[i])\n",
    "    kpList.append(kp)\n",
    "    desList.append(des)\n",
    "\n",
    "image_kp_1 = cv.drawKeypoints(\n",
    "    gray_0, kpList[0], images[0], flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    ")\n",
    "image_kp_2 = cv.drawKeypoints(\n",
    "    gray_1, kpList[1], images[1], flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    ")\n",
    "\n",
    "ifig, iaxs = plt.subplots(ncols=2, figsize=(8, 8))\n",
    "iaxs[0].imshow(image_kp_1)\n",
    "iaxs[1].imshow(image_kp_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Match features (brute-force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv.BFMatcher()\n",
    "\n",
    "# matches between index i and i+1\n",
    "bfMatchesList = []\n",
    "for i in range(numPoses - 1):\n",
    "    bf_matches = bf.knnMatch(desList[i], desList[i + 1], k=2)\n",
    "    good = []\n",
    "\n",
    "    for m, n in bf_matches:\n",
    "        if m.distance < 0.8 * n.distance:\n",
    "            good.append([m])\n",
    "    bfMatchesList.append(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1294\n"
     ]
    }
   ],
   "source": [
    "show_index = 18\n",
    "image_matches = cv.drawMatchesKnn(\n",
    "    images[show_index],\n",
    "    kpList[show_index],\n",
    "    images[show_index + 1],\n",
    "    kpList[show_index + 1],\n",
    "    bfMatchesList[show_index],\n",
    "    None,\n",
    "    flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    ")\n",
    "\n",
    "\n",
    "ifig, iax = plt.subplots()\n",
    "iax.imshow(image_matches)\n",
    "ifig.tight_layout()\n",
    "print(len(bfMatchesList[show_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# Estimate essential matrix, filter points with ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see pyrender script for intrinsic camera params\n",
    "intrinsic_mat = np.array([[2048, 0, 1024], [0, 2048, 1024], [0, 0, 1]])\n",
    "\n",
    "ransacMatches = []\n",
    "fMatrices = []\n",
    "for i in range(numPoses - 1):\n",
    "    good = bfMatchesList[i]\n",
    "    kp1 = kpList[i]\n",
    "    kp2 = kpList[i + 1]\n",
    "    points_1 = np.int32([kp1[m.queryIdx].pt for [m] in good]).reshape(-1, 1, 2)\n",
    "    points_2 = np.int32([kp2[m.trainIdx].pt for [m] in good]).reshape(-1, 1, 2)\n",
    "\n",
    "    fMatrix, mask = cv.findFundamentalMat(\n",
    "        points_1,\n",
    "        points_2,\n",
    "        method=cv.FM_RANSAC,\n",
    "        ransacReprojThreshold=3,\n",
    "        confidence=1 - 1e-6,\n",
    "    )\n",
    "\n",
    "    postRansac = []\n",
    "    if mask is not None:\n",
    "        for i in range(len(mask)):\n",
    "            if mask[i]:\n",
    "                postRansac.append(good[i])\n",
    "    else:\n",
    "        print(\"warning no points recovered for \" + str(i))\n",
    "    ransacMatches.append(postRansac)\n",
    "    fMatrices.append(fMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9554036   0.27377234  0.11069179 -0.86398621]\n",
      " [-0.27031095  0.96169977 -0.04544818  0.44675411]\n",
      " [-0.11889472  0.01350015  0.99281508 -0.23224684]]\n",
      "[[ 0.95105652  0.25916346  0.16830272  0.16830272]\n",
      " [-0.26761657  0.96308139  0.02925072  0.02925072]\n",
      " [-0.1545085  -0.07285969  0.98530127 -0.01469873]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essential_mat = intrinsic_mat.T @ fMatrices[0] @ intrinsic_mat\n",
    "\n",
    "good = ransacMatches[0]\n",
    "kp1 = kpList[0]\n",
    "kp2 = kpList[1]\n",
    "points_1 = np.int32([kp1[m.queryIdx].pt for [m] in good]).reshape(-1, 1, 2)\n",
    "points_2 = np.int32([kp2[m.trainIdx].pt for [m] in good]).reshape(-1, 1, 2)\n",
    "\n",
    "_, est_rot, est_trans, _ = cv.recoverPose(\n",
    "    essential_mat, points_1, points_2, intrinsic_mat\n",
    ")\n",
    "\n",
    "est_extrinsic = np.hstack((est_rot, est_trans))\n",
    "\n",
    "# act_rot = sci_trans.Rotation.align_vectors(dir_2, dir_1)[0].as_matrix()\n",
    "# act_extrinsic = np.hstack((act_rot, np.reshape(dir_2 - dir_1, (-1, 1))))\n",
    "# actual extrinsics\n",
    "# print(pose1)\n",
    "# print(pose2)\n",
    "relativePose = np.matmul(np.linalg.inv(poses[0]), poses[1])\n",
    "# print(relativePose)\n",
    "act_extrinsic = relativePose[0:3, :]\n",
    "print(est_extrinsic)\n",
    "print(act_extrinsic)\n",
    "\n",
    "origin = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "\n",
    "all_extrinsics = [origin, act_extrinsic, est_extrinsic]\n",
    "base_colors = [\n",
    "    mpl.colors.to_rgb(\"tab:blue\"),\n",
    "    mpl.colors.to_rgb(\"tab:green\"),\n",
    "    mpl.colors.to_rgb(\"tab:red\"),\n",
    "]\n",
    "cfig, cax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "for mat, color in zip(all_extrinsics, base_colors, strict=False):\n",
    "    pos = mat[:, 3]\n",
    "    for column, weight in zip(mat[:, :3].T, [1, 0.8, 0.5], strict=False):\n",
    "        cax.quiver(*pos, *column, color=np.array(color) * weight)\n",
    "\n",
    "cfig.tight_layout()\n",
    "cax.set_xlim3d(-1, 1)\n",
    "cax.set_ylim3d(-1, 1)\n",
    "cax.set_zlim3d(-1, 1)\n",
    "# cax.voxels(voxelarray, facecolors=colors, edgecolors=colors);\n",
    "\n",
    "# note: rotation vectors stay aligned and translation is close enough (within scale factor)\n",
    "# NOTE the chirality is messed up. pyrender camera has an inverted y axis. estimated translation will have the opposite direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1526175   0.04640891 -0.25359814]\n",
      " [ 0.14773066  0.05712462 -0.18378115]\n",
      " [ 0.15215749  0.0656781  -0.25708157]\n",
      " ...\n",
      " [-0.18209923 -0.04093154 -0.23561221]\n",
      " [-0.17659141 -0.07751344 -0.23867718]\n",
      " [-0.18203924 -0.06023267 -0.24103459]]\n",
      "[[ 0.15362999 -0.00089146 -0.20089768]\n",
      " [ 0.14975312  0.00631723 -0.2044812 ]\n",
      " [ 0.09249056  0.03568722 -0.46834355]\n",
      " ...\n",
      " [-0.20811178 -0.02238656 -0.30682372]\n",
      " [-0.21068337 -0.01582028 -0.30874559]\n",
      " [-0.21088518 -0.02911673 -0.29467801]]\n"
     ]
    }
   ],
   "source": [
    "# turn feature points into 3D points using actual extrinsic matrix\n",
    "points3DList = []\n",
    "quality3DPointsList = []\n",
    "highErrorPts = 0\n",
    "for i in range(numPoses - 1):\n",
    "    relativePose = np.matmul(np.linalg.inv(poses[i]), poses[i + 1])\n",
    "    R = relativePose[0:3, 0:3]\n",
    "    T = relativePose[0:3, 3]\n",
    "\n",
    "    kp1 = kpList[i]\n",
    "    kp2 = kpList[i + 1]\n",
    "    good = ransacMatches[i]\n",
    "\n",
    "    points_1_pr = np.int32([kp1[m.queryIdx].pt for [m] in good]).reshape(-1, 1, 2)\n",
    "    points_2_pr = np.int32([kp2[m.trainIdx].pt for [m] in good]).reshape(-1, 1, 2)\n",
    "    f = 2048.0\n",
    "    points3D = np.zeros((len(points_1_pr), 3))\n",
    "    currentPose = poses[i]\n",
    "    for index in range(len(points_1_pr)):\n",
    "        point1 = points_1_pr[index]\n",
    "        point2 = points_2_pr[index]\n",
    "        # NOTE inverting y axis here\n",
    "        # also converting from pixels to camera frame\n",
    "        ray1 = np.array([point1[0][0] - 1024, 1024 - point1[0][1], f])  # *a\n",
    "        ray2 = R @ np.array([point2[0][0] - 1024, 1024 - point2[0][1], f])\n",
    "        ray1 = ray1 / np.linalg.norm(ray1)\n",
    "        ray2 = ray2 / np.linalg.norm(ray2)\n",
    "        skewSegment = np.cross(ray1, ray2)\n",
    "        skewSegment = skewSegment / np.linalg.norm(skewSegment)\n",
    "        A = np.column_stack([ray1, -ray2, skewSegment])\n",
    "        coeffs = np.linalg.solve(A, T)\n",
    "\n",
    "        p13d = coeffs[0] * ray1\n",
    "        p23d = T + coeffs[1] * ray2\n",
    "        midpoint = (p13d + p23d) / 2.0\n",
    "\n",
    "        # convert to world coordinates\n",
    "        fourVec = np.concatenate([midpoint, [1]])\n",
    "        point_worldCoords = (currentPose @ fourVec)[0:3]\n",
    "        points3D[index] = point_worldCoords\n",
    "\n",
    "        # warning, arbitrary threshold for filtering high error points\n",
    "        if coeffs[2] / (np.linalg.norm(coeffs)) < 1e-2:\n",
    "            quality3DPointsList.append(point_worldCoords)\n",
    "\n",
    "    points3DList.append(points3D)\n",
    "print(points3DList[0])\n",
    "print(points3DList[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08856319 -0.01959212  0.00792353]\n"
     ]
    }
   ],
   "source": [
    "points3D = points3DList[18]\n",
    "print(points3D[0])\n",
    "# problem: sift feature points aren't always corners, not all corners make it to the final list either\n",
    "\n",
    "cfig, cax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "cax.scatter(points3D[:, 0], points3D[:, 1], points3D[:, 2])\n",
    "cfig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all pts\n",
    "cfig, cax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "for points3D in points3DList:\n",
    "    cax.scatter(points3D[:, 0], points3D[:, 1], points3D[:, 2])\n",
    "cfig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # actual mesh\n",
    "# coralFile = os.path.join(FILE_PATH, \"coral_4\", \"untitled.dae\")\n",
    "# mesh = trimesh.load(coralFile, force=\"mesh\")\n",
    "# pc1 = pcloud.generatePointCloud(mesh, noise=0.0)\n",
    "# clusters1 = pcloud.extractClusters(pc1, distance_threshold=0.5)\n",
    "\n",
    "# # Plot it\n",
    "# pl1 = pv.Plotter(shape=(1, 2))\n",
    "# pl1.add_title(\"Point Cloud of 3D Surface\")\n",
    "# pl1.add_mesh(pc1)\n",
    "# pl1.subplot(0, 1)\n",
    "# pl1.add_title(\"Reconstructed Surface\")\n",
    "# for cluster in clusters1:\n",
    "#     surf = pcloud.pointsToSurface(cluster)\n",
    "#     pl1.add_mesh(surf, color=True, show_edges=True)\n",
    "\n",
    "# uncomment this to show\n",
    "# pl1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1526175   0.04640891 -0.25359814]\n",
      " [ 0.14773066  0.05712462 -0.18378115]\n",
      " [ 0.15215749  0.0656781  -0.25708157]\n",
      " ...\n",
      " [-0.19217237  0.03611609 -0.20578269]\n",
      " [-0.190068    0.03676289 -0.21074208]\n",
      " [-0.19543211  0.04003542 -0.21145896]]\n",
      "40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7203c9262a845cbb25dc3ace997121e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:55064/index.html?ui=P_0x1f85f1a6290_17&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flattenedPointsList = np.array(quality3DPointsList)\n",
    "# flattenedPointsList = np.concatenate(points3DList)\n",
    "print(flattenedPointsList)\n",
    "print(numPoses)\n",
    "reconstructedMesh = pcloud.pointsToMesh(flattenedPointsList, \"open3d_alpha\", 0.1)\n",
    "\n",
    "# Plot it\n",
    "pl = pv.Plotter(shape=(1, 2))\n",
    "pl.add_title(\"Point Cloud of 3D Surface\")\n",
    "pl.add_mesh(flattenedPointsList)\n",
    "pl.subplot(0, 1)\n",
    "pl.add_title(\"Reconstructed Surface\")\n",
    "\n",
    "pl.add_mesh(reconstructedMesh, color=True, show_edges=True)\n",
    "\n",
    "# uncomment this to show\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95c9bec63214a298c36d6adb7e6e711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:55064/index.html?ui=P_0x1f86f3ff790_28&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate I over U\n",
    "\n",
    "# actual mesh\n",
    "coralFile = os.path.join(FILE_PATH, \"coral_4\", \"untitled.dae\")\n",
    "actualmesh = trimesh.load(coralFile, force=\"mesh\")\n",
    "\n",
    "# fudging the scale. somewhere along the line this gets messed up, and the signs all got flipped?\n",
    "scalar = 2.5\n",
    "vertices = [\n",
    "    np.array([-scalar * v[0], -scalar * v[1], -scalar * v[2]])\n",
    "    for v in actualmesh.vertices\n",
    "]\n",
    "\n",
    "actualmesh2 = pcloud.pointsToMesh(vertices, \"open3d_alpha\", 0.02 * scalar)\n",
    "\n",
    "# Plot it\n",
    "pl = pv.Plotter(shape=(1, 1))\n",
    "pl.add_title(\"Point Cloud of 3D Surface\")\n",
    "pl.add_mesh(reconstructedMesh, color=[255, 0, 0], show_edges=True, opacity=0.5)\n",
    "pl.add_mesh(actualmesh2, color=[0, 0, 255], show_edges=True, opacity=0.5)\n",
    "\n",
    "# uncomment this to show\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not all meshes are volumes!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m trimesh\u001b[38;5;241m.\u001b[39mrepair\u001b[38;5;241m.\u001b[39mfill_holes(actualmesh)\n\u001b[0;32m      4\u001b[0m trimesh\u001b[38;5;241m.\u001b[39mrepair\u001b[38;5;241m.\u001b[39mfix_normals(actualmesh) \n\u001b[1;32m----> 6\u001b[0m ratio \u001b[38;5;241m=\u001b[39m \u001b[43mpcloud\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintersectionOverUnion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactualmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactualmesh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(ratio)\n",
      "File \u001b[1;32mC:\\Code\\Project3DReconstruction\\src\\project_3d_reconstruction\\point_cloud_to_mesh\\point_cloud_to_mesh.py:132\u001b[0m, in \u001b[0;36mintersectionOverUnion\u001b[1;34m(mesh1, mesh2, engine)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mintersectionOverUnion\u001b[39m(mesh1, mesh2, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 132\u001b[0m     union \u001b[38;5;241m=\u001b[39m \u001b[43mtrimesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboolean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmesh1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m     intersection \u001b[38;5;241m=\u001b[39m trimesh\u001b[38;5;241m.\u001b[39mboolean\u001b[38;5;241m.\u001b[39mintersection([mesh1, mesh2], engine\u001b[38;5;241m=\u001b[39mengine)\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m intersection\u001b[38;5;241m.\u001b[39mvolume \u001b[38;5;241m/\u001b[39m union\u001b[38;5;241m.\u001b[39mvolume\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\trimesh\\boolean.py:75\u001b[0m, in \u001b[0;36munion\u001b[1;34m(meshes, engine, check_volume, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03mCompute the boolean union between a mesh an n other meshes.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m  A `Trimesh` that contains the union of all passed meshes.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_volume \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(m\u001b[38;5;241m.\u001b[39mis_volume \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m meshes):\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot all meshes are volumes!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m result \u001b[38;5;241m=\u001b[39m _engines[engine](meshes, operation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mValueError\u001b[0m: Not all meshes are volumes!"
     ]
    }
   ],
   "source": [
    "# meshes are not watertight\n",
    "# temporary fix could be to increase alpha until they are\n",
    "\n",
    "trimesh.repair.fix_winding(actualmesh)\n",
    "trimesh.repair.fix_inversion(actualmesh)\n",
    "trimesh.repair.fill_holes(actualmesh)\n",
    "trimesh.repair.fix_normals(actualmesh)\n",
    "\n",
    "# check with self to see if its watertight\n",
    "# ratio = pcloud.intersectionOverUnion(actualmesh,actualmesh)\n",
    "ratio = pcloud.intersectionOverUnion(actualmesh2, reconstructedMesh)\n",
    "print(ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
