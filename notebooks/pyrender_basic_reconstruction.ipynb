{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 3D reconstruction using 2 image\n",
    "\n",
    "Key References\n",
    "- https://www.opencvhelp.org/tutorials/advanced/reconstruction-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import TYPE_CHECKING\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyrender\n",
    "import scipy.spatial.transform as sci_trans\n",
    "\n",
    "import project_3d_reconstruction.mpl as proj_mpl\n",
    "from project_3d_reconstruction.rendering import render_helper as rh\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from mpl_toolkits.mplot3d.axes3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Generate simple scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Attempting to recreate the matplotlib one\n",
    "\"\"\"\n",
    "\n",
    "renderer = rh.RenderHelper()\n",
    "renderer.addCube(0.5, rh.positionOnly(-0.5, -0.5, -0.5), color=[255, 0, 0])\n",
    "renderer.addCube(0.4, rh.positionOnly(-0.4, 0.35, -0.6), color=[144, 144, 0])\n",
    "renderer.addCube(0.4, rh.positionOnly(-0.8, 0.35, -0.6), color=[144, 0, 144])\n",
    "renderer.addCube(0.4, rh.positionOnly(0.5, -0.35, 0.6), color=[0, 100, 144])\n",
    "renderer.addCube(0.2, rh.positionOnly(0.2, -0.43, -0.27), color=[144, 0, 144])\n",
    "renderer.addCube(0.2, rh.positionOnly(-0.263, 0.375, 0.03), color=[0, 0, 144])\n",
    "\n",
    "for i in [-0.2, 0, 0.2]:\n",
    "    renderer.addCube(0.3, rh.positionOnly(i, i, i), color=[50 + 200 * i, 255, 0])\n",
    "\n",
    "renderer.addCube(0.5, rh.positionOnly(0.5, 0.5, 0.5), color=[0, 0, 255])\n",
    "\n",
    "# TODO add more surface feature points/texture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Save image from two perspectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0, -0.2], [0, 0.7071067811865476, -0.7071067811865476, -2], [0, 0.7071067811865476, 0.7071067811865476, 2], [0, 0, 0, 1]]\n",
      "[[1, 0, 0, 0.2], [0, 0.7071067811865476, -0.7071067811865476, -2], [0, 0.7071067811865476, 0.7071067811865476, 2], [0, 0, 0, 1]]\n",
      "[[ 1.00000000e+00  0.00000000e+00  0.00000000e+00 -4.00000000e-01]\n",
      " [ 0.00000000e+00  1.00000000e+00 -1.01465364e-17  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.01465364e-17  1.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Render two views\n",
    "pose1 = rh.pointingAtOrigin(-0.2, 2)\n",
    "renderer.moveCamera(pose1)\n",
    "renderer.render(show_image=False, image_filename=\"test1.png\")\n",
    "\n",
    "pose2 = rh.pointingAtOrigin(0.2, 2)\n",
    "renderer.moveCamera(pose2)\n",
    "renderer.render(show_image=False, image_filename=\"test2.png\")\n",
    "\n",
    "image_1 = cv.imread(\"test1.png\")\n",
    "image_2 = cv.imread(\"test2.png\")\n",
    "\n",
    "# actual extrinsics\n",
    "print(pose1)\n",
    "print(pose2)\n",
    "relativePose = np.matmul(np.linalg.inv(pose2), pose1)\n",
    "print(relativePose)\n",
    "# camCopy = pyrender.IntrinsicsCamera(fx=512, fy=512, cx=256, cy=256)\n",
    "# print(camCopy.get_projection_matrix(width=512,height=512))\n",
    "\n",
    "gray_1 = cv.cvtColor(image_1, cv.COLOR_BGR2GRAY)\n",
    "gray_2 = cv.cvtColor(image_2, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "ifig, iaxs = plt.subplots(ncols=2, figsize=(8, 8))\n",
    "iaxs[0].imshow(image_1)\n",
    "iaxs[1].imshow(image_2)\n",
    "ifig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Detect SIFT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fe36787320>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def opponentSIFT(img):\n",
    "    # Step 1 convert to opponent color space\n",
    "    # TODO optimize\n",
    "    B = img[:, :, 0]\n",
    "    G = img[:, :, 1]\n",
    "    R = img[:, :, 2]\n",
    "\n",
    "    O1 = np.divide((R - G), np.sqrt(2))\n",
    "    O2 = np.divide((R + G - 2 * B), np.sqrt(6))\n",
    "    O3 = np.divide((R + G + B), np.sqrt(3))\n",
    "    # visually check opponent color space\n",
    "    # cv.imwrite('sift_keypointsO1.jpg',np.uint8(O1))\n",
    "    # cv.imwrite('sift_keypointsO2.jpg',np.uint8(O2))\n",
    "    # cv.imwrite('sift_keypointsO3.jpg',np.uint8(O3))\n",
    "\n",
    "    # Step 2 use Harris-Laplace point detector on intensity channel (o3)\n",
    "    # TODO use a real point detector or figure out what parameters to use with cv SIFT\n",
    "    # use this space to specify additional parameters\n",
    "    sift = cv.SIFT_create()\n",
    "    # sift = cv.SIFT_create(nfeatures=1000, nOctaveLayers=3, sigma=10)\n",
    "\n",
    "    kp = sift.detect(np.uint8(O3), None)\n",
    "\n",
    "    # Step 3 compute descriptors for each opponent channel\n",
    "    _, des1 = sift.compute(np.uint8(O1), kp)\n",
    "    _, des2 = sift.compute(np.uint8(O2), kp)\n",
    "    _, des3 = sift.compute(np.uint8(O3), kp)\n",
    "\n",
    "    # combine into one large descriptor\n",
    "    des = np.concatenate((des1, des2, des3), axis=1)\n",
    "\n",
    "    return kp, des\n",
    "\n",
    "\n",
    "kp1, des1 = opponentSIFT(image_1)\n",
    "kp2, des2 = opponentSIFT(image_2)\n",
    "\n",
    "image_kp_1 = cv.drawKeypoints(\n",
    "    gray_1, kp1, image_1, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    ")\n",
    "image_kp_2 = cv.drawKeypoints(\n",
    "    gray_2, kp2, image_2, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    ")\n",
    "\n",
    "ifig, iaxs = plt.subplots(ncols=2, figsize=(8, 8))\n",
    "iaxs[0].imshow(image_kp_1)\n",
    "iaxs[1].imshow(image_kp_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Match features (brute-force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv.BFMatcher()\n",
    "bf_matches = bf.knnMatch(des1, des2, k=2)\n",
    "good = []\n",
    "\n",
    "for m, n in bf_matches:\n",
    "    if m.distance < 0.8 * n.distance:\n",
    "        good.append([m])\n",
    "\n",
    "image_matches = cv.drawMatchesKnn(\n",
    "    image_1,\n",
    "    kp1,\n",
    "    image_2,\n",
    "    kp2,\n",
    "    good,\n",
    "    None,\n",
    "    flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    ")\n",
    "\n",
    "\n",
    "ifig, iax = plt.subplots()\n",
    "iax.imshow(image_matches)\n",
    "ifig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Estimate essential matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# points_1 = np.array([kp1[match.queryIdx].pt for [match] in good])[:, np.newaxis, :]\n",
    "# points_2 = np.array([kp2[match.trainIdx].pt for [match] in good])[:, np.newaxis, :]\n",
    "points_1 = np.int32([kp1[m.queryIdx].pt for [m] in good]).reshape(-1, 1, 2)\n",
    "points_2 = np.int32([kp2[m.trainIdx].pt for [m] in good]).reshape(-1, 1, 2)\n",
    "\n",
    "# see pyrender script for intrinsic camera params\n",
    "intrinsic_mat = np.array([[512, 0, 256], [0, 512, 256], [0, 0, 1]])\n",
    "essential_mat, mask = cv.findEssentialMat(\n",
    "    points_1, points_2, intrinsic_mat, method=cv.RANSAC, prob=1 - 1e-12, threshold=3\n",
    ")\n",
    "_, est_rot, est_trans, _ = cv.recoverPose(\n",
    "    essential_mat, points_1, points_2, intrinsic_mat, mask=mask\n",
    ")\n",
    "\n",
    "# check the matches kept by ransac - sometimes they're bad\n",
    "postRansac = []\n",
    "for i in range(len(mask)):\n",
    "    if mask[i]:\n",
    "        postRansac.append(good[i])\n",
    "print(len(good))\n",
    "print(len(postRansac))\n",
    "image_matches = cv.drawMatchesKnn(\n",
    "    image_1,\n",
    "    kp1,\n",
    "    image_2,\n",
    "    kp2,\n",
    "    postRansac,\n",
    "    None,\n",
    "    flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    ")\n",
    "\n",
    "ifig, iax = plt.subplots()\n",
    "iax.imshow(image_matches)\n",
    "ifig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99978913  0.01512054  0.01389451]\n",
      " [-0.01508983  0.99988347 -0.00231218]\n",
      " [-0.01392785  0.00210203  0.99990079]]\n",
      "[[-0.99996851]\n",
      " [ 0.00652723]\n",
      " [ 0.00451478]]\n"
     ]
    }
   ],
   "source": [
    "# check estimated extrinsic params\n",
    "print(est_rot)\n",
    "print(est_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99978913  0.01512054  0.01389451 -0.99996851]\n",
      " [-0.01508983  0.99988347 -0.00231218  0.00652723]\n",
      " [-0.01392785  0.00210203  0.99990079  0.00451478]]\n",
      "[[ 1.00000000e+00  0.00000000e+00  0.00000000e+00 -4.00000000e-01]\n",
      " [ 0.00000000e+00  1.00000000e+00 -1.01465364e-17  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.01465364e-17  1.00000000e+00  0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_extrinsic = np.hstack((est_rot, est_trans))\n",
    "\n",
    "# act_rot = sci_trans.Rotation.align_vectors(dir_2, dir_1)[0].as_matrix()\n",
    "# act_extrinsic = np.hstack((act_rot, np.reshape(dir_2 - dir_1, (-1, 1))))\n",
    "act_extrinsic = relativePose[0:3, :]\n",
    "print(est_extrinsic)\n",
    "print(act_extrinsic)\n",
    "\n",
    "origin = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "\n",
    "all_extrinsics = [origin, act_extrinsic, est_extrinsic]\n",
    "base_colors = [\n",
    "    mpl.colors.to_rgb(\"tab:blue\"),\n",
    "    mpl.colors.to_rgb(\"tab:green\"),\n",
    "    mpl.colors.to_rgb(\"tab:red\"),\n",
    "]\n",
    "cfig, cax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "for mat, color in zip(all_extrinsics, base_colors, strict=False):\n",
    "    pos = mat[:, 3]\n",
    "    for column, weight in zip(mat[:, :3].T, [1, 0.8, 0.5], strict=False):\n",
    "        cax.quiver(*pos, *column, color=np.array(color) * weight)\n",
    "\n",
    "cfig.tight_layout()\n",
    "cax.set_xlim3d(-1, 1)\n",
    "cax.set_ylim3d(-1, 1)\n",
    "cax.set_zlim3d(-1, 1)\n",
    "# cax.voxels(voxelarray, facecolors=colors, edgecolors=colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
